---
title: "Machine Learning Assignment"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This assignment is about predicting the manner how barlifts are lifted, i.e. measuring the quality of the exercise. The data for this project comes from the source http://groupware.les.inf.puc-rio.br/har.

**Important Note**: The html output, which supports a browser, can found here [panomarix.github.io](http://panomarix.github.io) and the markdown file in repository [https://github.com/panomarix/panomarix.github.io](https://github.com/panomarix/panomarix.github.io)

## Data Loading and preparation

```{r dataloading}
library(caret)
trainingdata <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testingdata <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
```

The "classe" indicates how well the exercise has been performed. The training dataset is to be used for training the model and testing it. The testingdata dataset includes data of 20 different test cases that have to be predicted with the trained.

At first we will perform some data preparation: by removing all NA's in the trainingdata, remove all Columns that have marginal variability and by removing irrelevant columns (e.g user name).

```{r datapreparation}
trainingdata <- trainingdata[ , colSums(is.na(trainingdata)) == 0]
zeroVarCols <- nearZeroVar(trainingdata,saveMetrics=TRUE)
trainingdata <- trainingdata[,!zeroVarCols$nzv]
IrrelevantCols <- grepl("X|user|timestamp|window",names(trainingdata))
trainingdata <- trainingdata[,!IrrelevantCols]
dim(trainingdata)
```

The dataset is therefore reduced to 53 columns, including the variable to predict.

## Training model 

I have opted to try out random forest, due to the high number of quantitive data and highly correlated values.
In order to also calculate an out of sample error later on, I split up the data in a training and testing dataset.

```{r modeltraining}
set.seed(3452)

inTrain <- createDataPartition(trainingdata$classe, p=0.7 , list=FALSE)
training <- trainingdata[inTrain,]
testing <-  trainingdata[-inTrain,]

control=trainControl(method="cv",number=5)
mod1 <- train(classe ~ ., method="rf", trControl=control , data=training)
mod1
```

The random forest model has an accuracy of 99.22 %.

## Cross validation

I now use the testset to calulate an out of sample error.

```{r crossvalidation}
prediction <- predict(mod1,testing)
confusionMatrix(testing$classe,prediction)
outOfSampleError <- sum(prediction!=testing$classe)/length(testing$classe)
outOfSampleError
```

The out of sample error is 0.7%. Which is fair enough for me.

## Prediction of 20 different test cases (Quiz input)

Part of the assignment is to predict the quality of how well 20 test cases were performed, as a preparation for the additional quiz.

```{r testcases}
testingdata2 <- testingdata[ , colSums(is.na(testingdata)) == 0] 
prediction2 <- predict(mod1,testingdata2)
prediction2
```


